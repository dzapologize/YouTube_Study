1
00:00:00,000 --> 00:00:02,340
在本视频中，我们将比较 golang 和

2
00:00:02,340 --> 00:00:04,140
Java 我们将

3
00:00:04,140 --> 00:00:06,060
基于 golang 的 fiber

4
00:00:06,060 --> 00:00:08,820
框架和 Java 的 spring boot 创建几个简单的应用程序，

5
00:00:08,820 --> 00:00:11,160
并使用 primitos 将它们部署到

6
00:00:11,160 --> 00:00:13,320
kubernetes 我们

7
00:00:13,320 --> 00:00:15,420
将从 Grass 中的 nginx 收集延迟和流量

8
00:00:15,420 --> 00:00:17,520
控制器来收集基本的容器

9
00:00:17,520 --> 00:00:20,100
指标，例如 CPU 使用率我们将部署

10
00:00:20,100 --> 00:00:22,380
CA Advisor 作为恶魔的应用程序您可以

11
00:00:22,380 --> 00:00:24,960
监控 CPU 使用率占

12
00:00:24,960 --> 00:00:26,880
给定容器

13
00:00:26,880 --> 00:00:29,640
以及 CPU 核心限制的百分比，并

14
00:00:29,640 --> 00:00:32,759
在 kubernetes 中将请求和限制绘制为线 由于

15
00:00:32,759 --> 00:00:35,280
使用了 c 组，因此测量

16
00:00:35,280 --> 00:00:37,860
CPU 节流至关重要，因为它会极大地

17
00:00:37,860 --> 00:00:39,540
影响

18
00:00:39,540 --> 00:00:41,760
应用程序的性能同样适用于内存，

19
00:00:41,760 --> 00:00:43,980
我们可以将其可视化为百分比或

20
00:00:43,980 --> 00:00:46,500
使用请求和限制的实际使用情况

21
00:00:46,500 --> 00:00:49,079
监控 nginx 也很重要

22
00:00:49,079 --> 00:00:51,539
ingrah 至少在 CPU

23
00:00:51,539 --> 00:00:53,760
使用方面发现它可能成为您应用程序的瓶颈，

24
00:00:53,760 --> 00:00:55,739
并且会显着

25
00:00:55,739 --> 00:00:58,260
增加延迟我们还将

26
00:00:58,260 --> 00:01:01,020
使用 nati 检测部分应用程序 ve

27
00:01:01,020 --> 00:01:03,239
parameters clients 例如在这个

28
00:01:03,239 --> 00:01:04,979
仪表板中我们将测量

29
00:01:04,979 --> 00:01:07,560
S3 调用和 mongodb 插入操作的请求持续时间，

30
00:01:07,560 --> 00:01:10,200
因为我们将使用

31
00:01:10,200 --> 00:01:12,600
基于开源 minion 项目的自托管 S3 解决方案

32
00:01:12,600 --> 00:01:14,700
我认为监控它是个

33
00:01:14,700 --> 00:01:16,920
好主意 primitos 同样，

34
00:01:16,920 --> 00:01:19,020
我们还将 mongodb 部署到

35
00:01:19,020 --> 00:01:21,180
kubernetes 中并使用 primitos exporter 对其进行监控，

36
00:01:21,180 --> 00:01:23,580
这些技术

37
00:01:23,580 --> 00:01:25,799
不仅可用于基准测试，而且可

38
00:01:25,799 --> 00:01:28,200
用于日常操作，您可以先

39
00:01:28,200 --> 00:01:29,880
在我的 GitHub 存储库中找到源代码，

40
00:01:29,880 --> 00:01:33,180
我们将 现在使用 terraform 创建 lbspc 和 eks

41
00:01:33,180 --> 00:01:35,520
以在 VPC 中公开我们的应用程序

42
00:01:35,520 --> 00:01:38,040
我们将

43
00:01:38,040 --> 00:01:40,320
使用 Helm

44
00:01:40,320 --> 00:01:42,960
chart 和 terraform 部署私有 nginx Ingress 控制器 然后将 go link

45
00:01:42,960 --> 00:01:45,420
和 Java 应用程序部署到 kubernetes 进行

46
00:01:45,420 --> 00:01:48,299
第一次测试 我们简单地使用 k6 负载

47
00:01:48,299 --> 00:01:50,399
测试工具进行比较 并排

48
00:01:50,399 --> 00:01:53,159
光纤和 spring boot 应用程序

49
00:01:53,159 --> 00:01:55,079
进行第二次更真实的测试，

50
00:01:55,079 --> 00:01:57,299
每个请求我们

51
00:01:57,299 --> 00:01:59,880
从 S3 存储桶下载图像并将最后

52
00:01:59,880 --> 00:02:02,399
修改日期保存到 m  ongodb 数据库

53
00:02:02,399 --> 00:02:04,920
现在让我们回顾一下代码，首先

54
00:02:04,920 --> 00:02:06,899
你可以找到 ciaform 代码来创建

55
00:02:06,899 --> 00:02:09,539
所有网络组件和

56
00:02:09,539 --> 00:02:12,000
AWS 环境中的 eks 然后我们有参数

57
00:02:12,000 --> 00:02:14,099
和其他监控组件，

58
00:02:14,099 --> 00:02:16,440
例如菜单能够

59
00:02:16,440 --> 00:02:18,840
在开箱即用时生成 primitos 矩阵 为了

60
00:02:18,840 --> 00:02:20,940
监控 mongodb，我们需要

61
00:02:20,940 --> 00:02:23,340
为第一次测试单独部署参数导出器，

62
00:02:23,340 --> 00:02:26,580
我们只需将 10 个设备返回

63
00:02:26,580 --> 00:02:28,800
给客户端，同样在 Java 中，这里我

64
00:02:28,800 --> 00:02:30,780
还包括了参数计数器

65
00:02:30,780 --> 00:02:32,819
变量，以防万一您想

66
00:02:32,819 --> 00:02:35,459
计算第二次调用此端点的次数

67
00:02:35,459 --> 00:02:37,980
在 go link 中测试我们有一个

68
00:02:37,980 --> 00:02:40,560
获取图像光纤处理程序，它使用

69
00:02:40,560 --> 00:02:43,140
下载功能从

70
00:02:43,140 --> 00:02:46,140
S3 存储桶中提取 S3 图像并保存功能以

71
00:02:46,140 --> 00:02:48,420
将最后修改日期插入到 mongodb

72
00:02:48,420 --> 00:02:51,120
现在共享 S3 客户端和 mongodb

73
00:02:51,120 --> 00:02:52,800
连接池我们创建一个自定义

74
00:02:52,800 --> 00:02:55,200
处理程序并添加 session 和 client

75
00:02:55,200 --> 00:02:57,660
属性，然后当我们初始化

76
00:02:57,660 --> 00:02:59,819
Handler 时，我们调用 helper 方法来

77
00:02:59,819 --> 00:03:01,920
建立与 S3 和

78
00:03:01,920 --> 00:03:04,140
mongodb 的连接 您不必共享 S3

79
00:03:04,140 --> 00:03:06,540
客户端，但每次访问 S3 时，

80
00:03:06,540 --> 00:03:09,239
它都会重新进行身份验证，这也需要

81
00:03:09,239 --> 00:03:11,280
时间，当涉及到 primitos

82
00:03:11,280 --> 00:03:13,379
Matrix 时，首先我们需要

83
00:03:13,379 --> 00:03:16,260
在结构中声明它们，然后创建新的 Matrix

84
00:03:16,260 --> 00:03:18,780
函数来初始化 他们在这个测试中

85
00:03:18,780 --> 00:03:21,900
我使用 summary 这对单个

86
00:03:21,900 --> 00:03:23,760
副本很好，你不必

87
00:03:23,760 --> 00:03:25,860
提前想出间隔桶

88
00:03:25,860 --> 00:03:27,659
但是如果你计划水平扩展这个

89
00:03:27,659 --> 00:03:29,700
应用程序你不能

90
00:03:29,700 --> 00:03:32,280
聚合 summary 而是使用

91
00:03:32,280 --> 00:03:34,260
直方图类型来记录

92
00:03:34,260 --> 00:03:36,959
您可以通过这种方式进行观察，只需记录

93
00:03:36,959 --> 00:03:39,120
函数调用之前和之后的时间，

94
00:03:39,120 --> 00:03:41,459
或者当然您可以使用中间件

95
00:03:41,459 --> 00:03:43,620
模式并包装此函数，这

96
00:03:43,620 --> 00:03:45,659
取决于您，当涉及到 Java 时，您

97
00:03:45,659 --> 00:03:48,299
遵循相同的原则在此声明矩阵

98
00:03:48,299 --> 00:03:51,239
如果我有 S3 和 mongodb 持续时间

99
00:03:51,239 --> 00:03:53,700
并使用它们来记录对

100
00:03:53,700 --> 00:03:56,220
Java 的观察，您需要添加一些依赖项

101
00:03:56,220 --> 00:03:58,379
，以允许您使用参数 Matrix

102
00:03:58,379 --> 00:04:00,840
来公开参数并指出您可以

103
00:04:00,840 --> 00:04:03,540
使用应用程序 .yaml 配置或仅

104
00:04:03,540 --> 00:04:06,060
在代码中使用 set 属性手动启用它

105
00:04:06,060 --> 00:04:08,760
最后让我们回顾一下第一个

106
00:04:08,760 --> 00:04:11,220
测试场景，我们将从一个

107
00:04:11,220 --> 00:04:14,159
虚拟用户开始，并在 5 分钟的间隔内慢慢将其扩展到 100 个

108
00:04:14,159 --> 00:04:17,160
用户，然后

109
00:04:17,160 --> 00:04:19,500
立即将用户数量

110
00:04:19,500 --> 00:04:22,680
增加到 500 并保持 5 分钟，然后

111
00:04:22,680 --> 00:04:26,040
在 5 分钟后将用户扩展到 3000，直到

112
00:04:26,040 --> 00:04:28,440
其中一个应用程序失败第二次

113
00:04:28,440 --> 00:04:30,660
测试是类似的，我们只是减少

114
00:04:30,660 --> 00:04:32,520
了客户端的数量并在不同的

115
00:04:32,520 --> 00:04:35,040
端点使用我还必须提到

116
00:04:35,040 --> 00:04:37,500
Java 现在有容器支持并且可以

117
00:04:37,500 --> 00:04:39,900
直接从 C 组获取限制，

118
00:04:39,900 --> 00:04:42,180
但是有些人仍然建议

119
00:04:42,180 --> 00:04:44,880
手动设置 Min 和 Max Heap 大小，

120
00:04:44,880 --> 00:04:47,400
而那些 Java Max 和 mean ram

121
00:04:47,400 --> 00:04:49,800
百分比非常令人困惑让我们

122
00:04:49,800 --> 00:04:51,780
继续运行第一个测试，因为您可以

123
00:04:51,780 --> 00:04:54,660
预期 Java CPU 使用率和内存

124
00:04:54,660 --> 00:04:57,120
使用率很高

125
00:04:57,120 --> 00:05:00,540
当我们达到每秒大约 600 个请求时，在这个简单的测试中比 go 更高

126
00:05:00,540 --> 00:05:02,699
Java 根本无法处理它们

127
00:05:02,699 --> 00:05:05,280
并拒绝请求这将

128
00:05:05,280 --> 00:05:07,020
在以下测试中改变 这个

129
00:05:07,020 --> 00:05:09,540
带有详细 CPU 使用情况的仪表板，您可以

130
00:05:09,540 --> 00:05:11,460
注意到 Java 进程受到了相当大的

131
00:05:11,460 --> 00:05:16,380
节流

132
00:05:21,180 --> 00:05:25,320
Ingress 控制器

133
00:05:25,320 --> 00:05:26,820
如果它们没有足够的

134
00:05:26,820 --> 00:05:29,039
资源，它们可能会导致延迟大幅增加，尤其是当您

135
00:05:29,039 --> 00:05:32,220
在测试结束时为 nginx Ingress 使用默认 Helm 图表

136
00:05:32,220 --> 00:05:34,620
时，您可以找到

137
00:05:34,620 --> 00:05:38,039
适用于 Java 的 P95 和 P90，然后让我们

138
00:05:38,039 --> 00:05:39,960
运行 第二次测试，当我们下载

139
00:05:39,960 --> 00:05:42,300
图像并在开始时保存最后修改日期时

140
00:05:42,300 --> 00:05:44,039
，您会注意到与

141
00:05:44,039 --> 00:05:46,620
第一次测试相同的模式

142
00:05:46,620 --> 00:05:49,199
，java 的 CPU 使用率更高，但是当我们

143
00:05:49,199 --> 00:05:51,419
达到每秒 20 个请求

144
00:05:51,419 --> 00:05:53,759
时，差异到最后会显着缩小

145
00:05:53,759 --> 00:05:55,380
当我们增加

146
00:05:55,380 --> 00:05:57,720
用户数量时，测试的目标 CPU 现在

147
00:05:57,720 --> 00:06:00,060
更高，这让我感到惊讶，而且

148
00:06:00,060 --> 00:06:02,699
延迟现在也

149
00:06:02,699 --> 00:06:05,160
一如既往地飙升这个测试只代表现实

150
00:06:05,160 --> 00:06:09,360
世界的场景

151
00:06:09,360 --> 00:06:12,000
由于我们使用

152
00:06:12,000 --> 00:06:14,340
大量外部库，它们在比较语言本身方面可能不是很准确，但是从 devops 的角度来看，

153
00:06:14,340 --> 00:06:18,300
当您在生产环境中运行应用程序时，它们可以向您展示真正的差异，

154
00:06:20,400 --> 00:06:22,860
如果您发现任何错误，这比斐波那契测试重要得多

155
00:06:22,860 --> 00:06:25,319
请让我知道，以便

156
00:06:25,319 --> 00:06:27,479
我可以在下一个视频中修复它们谢谢

157
00:06:27,479 --> 00:06:29,220
您的观看，

158
00:06:29,220 --> 00:06:31,520
下一个视频见
